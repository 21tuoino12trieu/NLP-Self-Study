{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.712372Z","iopub.execute_input":"2024-11-28T05:29:16.712737Z","iopub.status.idle":"2024-11-28T05:29:16.719694Z","shell.execute_reply.started":"2024-11-28T05:29:16.712705Z","shell.execute_reply":"2024-11-28T05:29:16.718264Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.722097Z","iopub.execute_input":"2024-11-28T05:29:16.722467Z","iopub.status.idle":"2024-11-28T05:29:16.739009Z","shell.execute_reply.started":"2024-11-28T05:29:16.722425Z","shell.execute_reply":"2024-11-28T05:29:16.737783Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"class LayerNormalization(nn.Module):\n    def __init__(self,emb_dim):\n        super().__init__()\n        self.eps = 1e-5\n        self.scale = nn.Parameter(torch.ones(emb_dim))\n        self.shift = nn.Parameter(torch.zeros(emb_dim))\n\n    def forward(self,x):\n        mean = x.mean(dim = -1,keepdim = True)\n        var = x.var(dim = -1,keepdim = True,unbiased = False)\n        norm_x = (x-mean)/torch.sqrt(var+self.eps)\n        return self.scale*norm_x+self.shift","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.740274Z","iopub.execute_input":"2024-11-28T05:29:16.740602Z","iopub.status.idle":"2024-11-28T05:29:16.750401Z","shell.execute_reply.started":"2024-11-28T05:29:16.740570Z","shell.execute_reply":"2024-11-28T05:29:16.749141Z"}},"outputs":[],"execution_count":68},{"cell_type":"code","source":"class GELU(nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,x):\n        return 0.5 * x * (1 + torch.tanh(\n            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n            (x + 0.044715 * torch.pow(x, 3))\n        ))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.751706Z","iopub.execute_input":"2024-11-28T05:29:16.752058Z","iopub.status.idle":"2024-11-28T05:29:16.768399Z","shell.execute_reply.started":"2024-11-28T05:29:16.752024Z","shell.execute_reply":"2024-11-28T05:29:16.767256Z"}},"outputs":[],"execution_count":69},{"cell_type":"code","source":"class FeedForward(nn.Module):\n    def __init__(self,d_model,dropout):\n        super().__init__()\n        self.d_model = d_model\n        self.layers = nn.Sequential(\n            nn.Linear(self.d_model,4*self.d_model),\n            GELU(),\n            nn.Linear(4*self.d_model,self.d_model)\n        )\n    def forward(self,x):\n        return self.layers(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.771031Z","iopub.execute_input":"2024-11-28T05:29:16.771571Z","iopub.status.idle":"2024-11-28T05:29:16.784168Z","shell.execute_reply.started":"2024-11-28T05:29:16.771519Z","shell.execute_reply":"2024-11-28T05:29:16.782666Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"class Embedding(nn.Module):\n    def __init__(self,d_model,vocab_size,max_seq_len,n_segments):\n        super().__init__()\n        self.tok_emb = nn.Embedding(vocab_size,d_model)\n        self.pos_emb = nn.Embedding(max_seq_len,d_model)\n        self.seg_emb = nn.Embedding(n_segments,d_model)\n        self.norm = LayerNormalization(d_model)\n    def forward(self,x,seg):\n        seq_len = x.size(1)\n        pos = torch.arange(seq_len,dtype=torch.long)\n        pos = pos.unsqueeze(0).expand_as(x) # (seq_len,) -> (batch_size, seq_len)\n        embedding = self.tok_emb(x) + self.pos_emb(pos) + self.seg_emb(seg)\n        return self.norm(embedding)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.809882Z","iopub.execute_input":"2024-11-28T05:29:16.810998Z","iopub.status.idle":"2024-11-28T05:29:16.818182Z","shell.execute_reply.started":"2024-11-28T05:29:16.810920Z","shell.execute_reply":"2024-11-28T05:29:16.816909Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"class BERTMultiheadAttention(nn.Module):\n    def __init__(self, d_model, num_heads, dropout):\n        super().__init__()\n        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n        \n        self.d_model = d_model\n        self.num_heads = num_heads\n        self.head_dim = d_model // num_heads\n\n        # Linear projections for Query, Key, Value\n        self.W_query = nn.Linear(d_model, d_model, bias=False)\n        self.W_key = nn.Linear(d_model, d_model, bias=False)\n        self.W_value = nn.Linear(d_model, d_model, bias=False)\n        self.out_prj = nn.Linear(d_model, d_model, bias=False)\n\n        # Dropout for regularization\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, attention_mask=None):\n        \"\"\"\n        x: Input tensor of shape (batch_size, seq_len, d_model)\n        attention_mask: Mask of shape (batch_size, seq_len), where 1 indicates valid tokens and 0 indicates padding.\n        \"\"\"\n        b, seq_len, _ = x.shape\n\n        # Compute Q, K, V\n        queries = self.W_query(x)  # Shape: (batch_size, seq_len, d_model)\n        keys = self.W_key(x)\n        values = self.W_value(x)\n\n        # Split into multiple heads\n        queries = queries.view(b, seq_len, self.num_heads, self.head_dim).transpose(1, 2)  # (b, num_heads, seq_len, head_dim)\n        keys = keys.view(b, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n        values = values.view(b, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n\n        # Compute scaled dot-product attention\n        attn_scores = torch.matmul(queries, keys.transpose(-2, -1))  # (b, num_heads, seq_len, seq_len)\n        attn_scores = attn_scores / (self.head_dim ** 0.5)  # Scale by sqrt(d_k)\n\n        # Apply attention mask\n        if attention_mask is not None:\n            # Expand mask to match attention scores shape\n            # attention_mask: (b, seq_len) -> (b, 1, 1, seq_len)\n            attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n            attn_scores = attn_scores.masked_fill(attention_mask == 0, -torch.inf)\n\n        # Compute attention weights\n        attn_weights = torch.softmax(attn_scores, dim=-1)  # (b, num_heads, seq_len, seq_len)\n        attn_weights = self.dropout(attn_weights)\n\n        # Compute context vector\n        context = torch.matmul(attn_weights, values)  # (b, num_heads, seq_len, head_dim)\n        context = context.transpose(1, 2).contiguous()  # (b, seq_len, num_heads, head_dim)\n        context = context.view(b, seq_len, self.d_model)  # Combine heads\n\n        # Output projection\n        output = self.out_prj(context)\n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.820483Z","iopub.execute_input":"2024-11-28T05:29:16.820866Z","iopub.status.idle":"2024-11-28T05:29:16.835975Z","shell.execute_reply.started":"2024-11-28T05:29:16.820827Z","shell.execute_reply":"2024-11-28T05:29:16.834851Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class TransformerEncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, dropout):\n        super().__init__()\n        self.attention = BERTMultiheadAttention(d_model, num_heads, dropout)\n        self.norm1 = LayerNormalization(d_model)\n        self.dropout1 = nn.Dropout(dropout)\n        \n        self.feed_forward = FeedForward(d_model, dropout)\n        self.norm2 = LayerNormalization(d_model)\n        self.dropout2 = nn.Dropout(dropout)\n\n    def forward(self, x, attention_mask=None):\n        # Multihead Attention + Residual Connection + LayerNorm\n        attn_output = self.attention(x, attention_mask)\n        x = self.norm1(x + self.dropout1(attn_output))\n        \n        # Feed Forward + Residual Connection + LayerNorm\n        ff_output = self.feed_forward(x)\n        x = self.norm2(x + self.dropout2(ff_output))\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.853121Z","iopub.execute_input":"2024-11-28T05:29:16.853512Z","iopub.status.idle":"2024-11-28T05:29:16.861045Z","shell.execute_reply.started":"2024-11-28T05:29:16.853477Z","shell.execute_reply":"2024-11-28T05:29:16.859848Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"class TransformerEncoder(nn.Module):\n    def __init__(self, d_model, num_heads, num_layers, dropout):\n        super().__init__()\n        self.layers = nn.ModuleList([\n            TransformerEncoderLayer(d_model, num_heads, dropout) for _ in range(num_layers)\n        ])\n\n    def forward(self, x, attention_mask=None):\n        for layer in self.layers:\n            x = layer(x, attention_mask)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.863163Z","iopub.execute_input":"2024-11-28T05:29:16.863551Z","iopub.status.idle":"2024-11-28T05:29:16.874385Z","shell.execute_reply.started":"2024-11-28T05:29:16.863508Z","shell.execute_reply":"2024-11-28T05:29:16.873211Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"class BERT(nn.Module):\n    def __init__(self, d_model, vocab_size, max_seq_len, n_segments, num_heads, num_layers, dropout):\n        super().__init__()\n        self.embedding = Embedding(d_model, vocab_size, max_seq_len, n_segments)\n        self.encoder = TransformerEncoder(d_model, num_heads, num_layers, dropout)\n\n    def forward(self, input_ids, segment_ids, attention_mask=None):\n        # Step 1: Embedding\n        x = self.embedding(input_ids, segment_ids)\n        \n        # Step 2: Transformer Encoder\n        x = self.encoder(x, attention_mask)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.875492Z","iopub.execute_input":"2024-11-28T05:29:16.875887Z","iopub.status.idle":"2024-11-28T05:29:16.888151Z","shell.execute_reply.started":"2024-11-28T05:29:16.875824Z","shell.execute_reply":"2024-11-28T05:29:16.886573Z"}},"outputs":[],"execution_count":75},{"cell_type":"code","source":"d_model = 64\nvocab_size = 30522\nmax_seq_len = 128\nn_segments = 2\nnum_heads = 8\nnum_layers = 6\ndropout = 0.1\n\nmodel = BERT(d_model=d_model, vocab_size=vocab_size, max_seq_len=max_seq_len,\n             n_segments=n_segments, num_heads=num_heads, num_layers=num_layers, dropout=dropout)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.890000Z","iopub.execute_input":"2024-11-28T05:29:16.890450Z","iopub.status.idle":"2024-11-28T05:29:16.934364Z","shell.execute_reply.started":"2024-11-28T05:29:16.890402Z","shell.execute_reply":"2024-11-28T05:29:16.933037Z"}},"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"BERT(\n  (embedding): Embedding(\n    (tok_emb): Embedding(30522, 64)\n    (pos_emb): Embedding(128, 64)\n    (seg_emb): Embedding(2, 64)\n    (norm): LayerNormalization()\n  )\n  (encoder): TransformerEncoder(\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayer(\n        (attention): BERTMultiheadAttention(\n          (W_query): Linear(in_features=64, out_features=64, bias=False)\n          (W_key): Linear(in_features=64, out_features=64, bias=False)\n          (W_value): Linear(in_features=64, out_features=64, bias=False)\n          (out_prj): Linear(in_features=64, out_features=64, bias=False)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (norm1): LayerNormalization()\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (feed_forward): FeedForward(\n          (layers): Sequential(\n            (0): Linear(in_features=64, out_features=256, bias=True)\n            (1): GELU()\n            (2): Linear(in_features=256, out_features=64, bias=True)\n          )\n        )\n        (norm2): LayerNormalization()\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n)"},"metadata":{}}],"execution_count":76},{"cell_type":"code","source":"batch_size = 2\nseq_len = 10  # Chiều dài chuỗi đầu vào\n\n# input_ids chứa các token ID\ninput_ids = torch.randint(0, vocab_size, (batch_size, seq_len))  # (batch_size, seq_len)\n\n# segment_ids phân biệt câu A (0) và câu B (1)\nsegment_ids = torch.randint(0, n_segments, (batch_size, seq_len))  # (batch_size, seq_len)\n\n# attention_mask chỉ định token nào là thật (1) và padding (0)\nattention_mask = torch.tensor([\n    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],  # Dòng 1: 5 token thật, 5 token padding\n    [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],  # Dòng 2: 4 token thật, 6 token padding\n])\noutput = model(input_ids, segment_ids, attention_mask)\noutput","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-28T05:29:16.936663Z","iopub.execute_input":"2024-11-28T05:29:16.937055Z","iopub.status.idle":"2024-11-28T05:29:17.085999Z","shell.execute_reply.started":"2024-11-28T05:29:16.937018Z","shell.execute_reply":"2024-11-28T05:29:17.084750Z"}},"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"tensor([[[ 7.2763e-04, -2.7103e+00,  1.1278e+00,  ..., -3.4072e-01,\n          -6.3131e-01,  1.5203e-01],\n         [-4.9745e-01, -1.0996e+00,  8.4621e-01,  ...,  9.9676e-01,\n           2.9121e-01,  6.2709e-01],\n         [ 4.8468e-01, -1.2053e+00,  9.1026e-01,  ..., -4.7352e-01,\n          -1.2227e-01,  2.6009e-02],\n         ...,\n         [ 2.0146e+00, -2.3029e+00,  2.9124e-01,  ...,  3.7293e-01,\n           1.4887e-02,  8.8913e-01],\n         [ 9.6224e-01, -1.5969e+00,  1.5195e+00,  ..., -4.8423e-02,\n          -1.2846e+00, -2.3044e-02],\n         [-7.8419e-01, -1.9584e+00,  1.4113e+00,  ..., -1.7711e-01,\n          -1.6480e+00,  2.2315e-01]],\n\n        [[ 1.9133e-01, -2.0663e+00,  1.3880e+00,  ..., -1.2733e+00,\n          -9.7928e-01, -5.2106e-01],\n         [ 5.3954e-02, -2.5436e+00,  4.3138e-01,  ...,  5.3130e-01,\n           2.0112e-01,  1.8335e+00],\n         [ 6.6519e-03, -1.3078e+00,  1.7699e-01,  ..., -1.9498e-02,\n           4.7979e-01,  8.5968e-01],\n         ...,\n         [ 7.5574e-01, -6.2779e-01, -6.3456e-01,  ...,  6.3348e-01,\n           6.1669e-01,  1.9677e+00],\n         [ 1.0135e+00, -2.6528e+00,  1.6081e+00,  ..., -1.0380e+00,\n          -1.6284e+00,  1.6319e+00],\n         [-5.1697e-01, -3.7627e-01, -5.9344e-01,  ..., -6.4976e-01,\n           3.4212e-01,  7.0234e-01]]], grad_fn=<AddBackward0>)"},"metadata":{}}],"execution_count":77}]}