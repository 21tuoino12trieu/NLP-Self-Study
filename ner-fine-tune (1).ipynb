{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8596251,"sourceType":"datasetVersion","datasetId":5142624},{"sourceId":10156449,"sourceType":"datasetVersion","datasetId":6270812}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:38.150680Z","iopub.execute_input":"2024-12-17T03:33:38.151008Z","iopub.status.idle":"2024-12-17T03:33:38.485784Z","shell.execute_reply.started":"2024-12-17T03:33:38.150978Z","shell.execute_reply":"2024-12-17T03:33:38.484714Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/ner-covid-19/dev_word.conll\n/kaggle/input/ner-covid-19/train_word.conll\n/kaggle/input/ner-covid-19/test_word.conll\n/kaggle/input/covid19-ner/test_word.json\n/kaggle/input/covid19-ner/dev_word.json\n/kaggle/input/covid19-ner/train_word.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torcheval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:38.487493Z","iopub.execute_input":"2024-12-17T03:33:38.487962Z","iopub.status.idle":"2024-12-17T03:33:48.213248Z","shell.execute_reply.started":"2024-12-17T03:33:38.487922Z","shell.execute_reply":"2024-12-17T03:33:48.212190Z"}},"outputs":[{"name":"stdout","text":"Collecting torcheval\n  Downloading torcheval-0.0.7-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torcheval) (4.12.2)\nDownloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: torcheval\nSuccessfully installed torcheval-0.0.7\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport transformers\nimport torch\nimport torch.nn as nn\n\nfrom sklearn import preprocessing\nfrom sklearn import model_selection\nfrom torcheval.metrics.functional import multiclass_f1_score\nfrom transformers import get_linear_schedule_with_warmup\n\nfrom tqdm import tqdm\nfrom transformers import AdamW","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:48.214703Z","iopub.execute_input":"2024-12-17T03:33:48.214999Z","iopub.status.idle":"2024-12-17T03:33:54.393733Z","shell.execute_reply.started":"2024-12-17T03:33:48.214971Z","shell.execute_reply":"2024-12-17T03:33:54.392820Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class config:\n    MAX_LEN = 128\n    TRAIN_BATCH_SIZE = 16\n    VALID_BATCH_SIZE = 16\n    EPOCH = 20\n    SEED = 42\n    BASE_MODEL = \"vinai/phobert-base-v2\"\n    TRAIN = \"/kaggle/input/ner-covid-19/train_word.conll\"\n\n    TOKENIZE = transformers.AutoTokenizer.from_pretrained(\n        BASE_MODEL,\n        do_lower_case = True\n    )\ntorch.manual_seed(config.SEED)\ntorch.cuda.manual_seed(config.SEED)\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:54.395581Z","iopub.execute_input":"2024-12-17T03:33:54.395971Z","iopub.status.idle":"2024-12-17T03:33:57.499239Z","shell.execute_reply.started":"2024-12-17T03:33:54.395945Z","shell.execute_reply":"2024-12-17T03:33:57.498295Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/678 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc00eda21b94b609f0273fc55a239f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff14efc91b2d4d76a7dde96535264b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf350882976345168920ed6f4b715239"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4eca51bc2ec04206af2bc55af2718444"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"def read_conll(file_path):\n    sentences = []\n    sentence = []\n\n    with open(file_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            line = line.strip()\n            if line == \"\":  \n                if sentence:\n                    sentences.append(sentence)\n                    sentence = []\n            else:\n                sentence.append(line.split()) \n    if sentence:\n        sentences.append(sentence)\n\n    return sentences\n\nfile_path = '/kaggle/input/ner-covid-19/train_word.conll'\nsentences = read_conll(file_path)\n\nprint(sentences[:2])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:57.500486Z","iopub.execute_input":"2024-12-17T03:33:57.501055Z","iopub.status.idle":"2024-12-17T03:33:57.788708Z","shell.execute_reply.started":"2024-12-17T03:33:57.501015Z","shell.execute_reply":"2024-12-17T03:33:57.787844Z"}},"outputs":[{"name":"stdout","text":"[[['Đồng_thời', 'O'], [',', 'O'], ['bệnh_viện', 'O'], ['tiếp_tục', 'O'], ['thực_hiện', 'O'], ['các', 'O'], ['biện_pháp', 'O'], ['phòng_chống', 'O'], ['dịch_bệnh', 'O'], ['COVID', 'O'], ['-', 'O'], ['19', 'O'], ['theo', 'O'], ['hướng_dẫn', 'O'], ['của', 'O'], ['Bộ', 'B-ORGANIZATION'], ['Y_tế', 'I-ORGANIZATION'], ['.', 'O']], [['\"', 'O'], ['Số', 'O'], ['bệnh_viện', 'O'], ['có_thể', 'O'], ['tiếp_nhận', 'O'], ['bệnh_nhân', 'O'], ['bị', 'O'], ['sốt', 'B-SYMPTOM_AND_DISEASE'], ['cao', 'I-SYMPTOM_AND_DISEASE'], ['và', 'O'], ['khó', 'B-SYMPTOM_AND_DISEASE'], ['thở', 'I-SYMPTOM_AND_DISEASE'], ['đang', 'O'], ['giảm', 'O'], ['dần', 'O'], ['\"', 'O'], [',', 'O'], ['thông_cáo', 'O'], ['có', 'O'], ['đoạn', 'O'], [',', 'O'], ['cảnh_báo', 'O'], ['những', 'O'], ['bệnh_nhân', 'O'], ['này', 'O'], ['thay', 'O'], ['vào', 'O'], ['đó', 'O'], ['được', 'O'], ['chuyển', 'O'], ['tới', 'O'], ['các', 'O'], ['phòng_khám', 'O'], ['khẩn_cấp', 'O'], [',', 'O'], ['khiến', 'O'], ['những', 'O'], ['bệnh_nhân', 'O'], ['mắc', 'O'], ['bệnh', 'O'], ['hiểm_nghèo', 'O'], ['khác', 'O'], ['không', 'O'], ['có', 'O'], ['cơ_hội', 'O'], ['được', 'O'], ['điều_trị', 'O'], ['.', 'O']]]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import pandas as pd\n\ndef conll_to_dataframe(sentences, columns):\n    data = []\n    for sentence in sentences:\n        for token in sentence:\n            data.append(dict(zip(columns, token)))\n\n    return pd.DataFrame(data)\n\ncolumns = [\"Word\", \"NER\"]\n\ndf = conll_to_dataframe(sentences, columns)\n\ndf.head(20)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:57.789825Z","iopub.execute_input":"2024-12-17T03:33:57.790100Z","iopub.status.idle":"2024-12-17T03:33:57.950202Z","shell.execute_reply.started":"2024-12-17T03:33:57.790074Z","shell.execute_reply":"2024-12-17T03:33:57.949389Z"},"scrolled":true},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"           Word             NER\n0     Đồng_thời               O\n1             ,               O\n2     bệnh_viện               O\n3      tiếp_tục               O\n4     thực_hiện               O\n5           các               O\n6     biện_pháp               O\n7   phòng_chống               O\n8     dịch_bệnh               O\n9         COVID               O\n10            -               O\n11           19               O\n12         theo               O\n13    hướng_dẫn               O\n14          của               O\n15           Bộ  B-ORGANIZATION\n16         Y_tế  I-ORGANIZATION\n17            .               O\n18            \"               O\n19           Số               O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Đồng_thời</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bệnh_viện</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tiếp_tục</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thực_hiện</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>các</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>biện_pháp</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>phòng_chống</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dịch_bệnh</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>COVID</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>19</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>theo</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>hướng_dẫn</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>của</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Bộ</td>\n      <td>B-ORGANIZATION</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Y_tế</td>\n      <td>I-ORGANIZATION</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>\"</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Số</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df[\"NER\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:57.951197Z","iopub.execute_input":"2024-12-17T03:33:57.951427Z","iopub.status.idle":"2024-12-17T03:33:57.972321Z","shell.execute_reply.started":"2024-12-17T03:33:57.951404Z","shell.execute_reply":"2024-12-17T03:33:57.971563Z"},"scrolled":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"NER\nO                        104750\nB-LOCATION                 5398\nI-LOCATION                 5242\nB-PATIENT_ID               3240\nB-DATE                     2549\nI-ORGANIZATION             2545\nI-DATE                     2500\nI-SYMPTOM_AND_DISEASE      1552\nB-SYMPTOM_AND_DISEASE      1439\nB-ORGANIZATION             1137\nB-AGE                       682\nB-GENDER                    542\nB-NAME                      349\nB-TRANSPORTATION            226\nB-JOB                       205\nI-TRANSPORTATION             67\nI-JOB                        62\nI-NAME                       13\nI-PATIENT_ID                 11\nI-AGE                         2\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(len(df))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:57.973226Z","iopub.execute_input":"2024-12-17T03:33:57.973498Z","iopub.status.idle":"2024-12-17T03:33:57.977946Z","shell.execute_reply.started":"2024-12-17T03:33:57.973440Z","shell.execute_reply":"2024-12-17T03:33:57.977145Z"}},"outputs":[{"name":"stdout","text":"132511\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"df[\"NER\"] = df[\"NER\"].replace(np.nan,\"nan\")\ndf = df[df[\"NER\"].str.isupper()]\n\nuppercase_rows = df[\"Word\"].notna()&df[\"Word\"].str.isupper()\ndf = df[~uppercase_rows]\nprint(len(df))\ndf.head(15)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:57.979128Z","iopub.execute_input":"2024-12-17T03:33:57.979949Z","iopub.status.idle":"2024-12-17T03:33:58.073339Z","shell.execute_reply.started":"2024-12-17T03:33:57.979922Z","shell.execute_reply":"2024-12-17T03:33:58.072502Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"129760\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"           Word             NER\n0     Đồng_thời               O\n1             ,               O\n2     bệnh_viện               O\n3      tiếp_tục               O\n4     thực_hiện               O\n5           các               O\n6     biện_pháp               O\n7   phòng_chống               O\n8     dịch_bệnh               O\n10            -               O\n11           19               O\n12         theo               O\n13    hướng_dẫn               O\n14          của               O\n15           Bộ  B-ORGANIZATION","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Đồng_thời</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bệnh_viện</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tiếp_tục</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thực_hiện</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>các</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>biện_pháp</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>phòng_chống</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>dịch_bệnh</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>-</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>19</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>theo</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>hướng_dẫn</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>của</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Bộ</td>\n      <td>B-ORGANIZATION</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"    sentence_number = 1\n    sentence_column = []\n    \n    for index,row in df.iterrows():\n        if row[\"Word\"] in {\".\",\"!\",\"?\"}:\n            sentence_number += 1\n        sentence_column.append(f\"Sentence: {sentence_number}\")\n    df[\"Sentence #\"] = sentence_column\n    df = df.reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:33:58.076441Z","iopub.execute_input":"2024-12-17T03:33:58.076898Z","iopub.status.idle":"2024-12-17T03:34:03.081067Z","shell.execute_reply.started":"2024-12-17T03:33:58.076862Z","shell.execute_reply":"2024-12-17T03:34:03.080349Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.082026Z","iopub.execute_input":"2024-12-17T03:34:03.082293Z","iopub.status.idle":"2024-12-17T03:34:03.096201Z","shell.execute_reply.started":"2024-12-17T03:34:03.082268Z","shell.execute_reply":"2024-12-17T03:34:03.095110Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"             Word NER      Sentence #\n0       Đồng_thời   O     Sentence: 1\n1               ,   O     Sentence: 1\n2       bệnh_viện   O     Sentence: 1\n3        tiếp_tục   O     Sentence: 1\n4       thực_hiện   O     Sentence: 1\n...           ...  ..             ...\n129755          ,   O  Sentence: 4978\n129756    kết_quả   O  Sentence: 4978\n129757       nghi   O  Sentence: 4978\n129758      nhiễm   O  Sentence: 4978\n129759          .   O  Sentence: 4979\n\n[129760 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n      <th>Sentence #</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Đồng_thời</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>,</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>bệnh_viện</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tiếp_tục</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>thực_hiện</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>129755</th>\n      <td>,</td>\n      <td>O</td>\n      <td>Sentence: 4978</td>\n    </tr>\n    <tr>\n      <th>129756</th>\n      <td>kết_quả</td>\n      <td>O</td>\n      <td>Sentence: 4978</td>\n    </tr>\n    <tr>\n      <th>129757</th>\n      <td>nghi</td>\n      <td>O</td>\n      <td>Sentence: 4978</td>\n    </tr>\n    <tr>\n      <th>129758</th>\n      <td>nhiễm</td>\n      <td>O</td>\n      <td>Sentence: 4978</td>\n    </tr>\n    <tr>\n      <th>129759</th>\n      <td>.</td>\n      <td>O</td>\n      <td>Sentence: 4979</td>\n    </tr>\n  </tbody>\n</table>\n<p>129760 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"class COVIDDataset:\n    def __init__(self,word,ner):\n        self.word = word\n        self.ner = ner\n    def __len__(self):\n        return len(self.word)\n    def __getitem__(self,item):\n        word = self.word[item]\n        ner = self.ner[item]\n\n        ids = []\n        target_ner = []\n    \n        for idx,str in enumerate(word):\n            inputs = config.TOKENIZE.encode(str,add_special_tokens = False)\n            input_len = len(inputs)\n            ids.extend(inputs)\n            target_ner.extend([ner[idx]] * input_len)\n    \n        ids = ids[:(config.MAX_LEN - 2)]\n        target_ner = target_ner[:(config.MAX_LEN - 2)]\n    \n        ids = [0] + ids + [2]\n        target_ner = [1] + target_ner +[1]\n    \n        mask = [1] * len(ids)\n        token_type_ids = [0] * len(ids)\n    \n        padding_len = config.MAX_LEN - len(ids)\n    \n        ids = ids + [1]*padding_len\n        mask = mask +[0]*padding_len\n        token_type_ids = token_type_ids + [0]*padding_len\n        target_ner = target_ner + [1]*padding_len\n    \n        return {\n            \"ids\":torch.tensor(ids, dtype = torch.long),\n            \"mask\":torch.tensor(mask, dtype = torch.long),\n            \"token_type_ids\":torch.tensor(token_type_ids, dtype = torch.long),\n            \"target_ner\":torch.tensor(target_ner, dtype = torch.long)\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.097371Z","iopub.execute_input":"2024-12-17T03:34:03.097772Z","iopub.status.idle":"2024-12-17T03:34:03.109942Z","shell.execute_reply.started":"2024-12-17T03:34:03.097739Z","shell.execute_reply":"2024-12-17T03:34:03.109166Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def process_data(df):\n    enc_ner = preprocessing.LabelEncoder()\n    # Các attribute của LabelEncoder():\n    # fit(): Tạo ra một list liệt kê các NER\n    # transform(): Biến đổi list các NER thành các số nguyên\n    # inverse_transform(): Biến đổi ngược các số nguyên thành list các NER\n    # fit_transform(): là bước kết hợp fit và transform\n    df.loc[:,\"NER\"] = enc_ner.fit_transform(df[\"NER\"])\n\n    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n    ner = df.groupby(\"Sentence #\")[\"NER\"].apply(list).values\n\n    return sentences, ner, enc_ner","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.110995Z","iopub.execute_input":"2024-12-17T03:34:03.111277Z","iopub.status.idle":"2024-12-17T03:34:03.124886Z","shell.execute_reply.started":"2024-12-17T03:34:03.111237Z","shell.execute_reply":"2024-12-17T03:34:03.124081Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_fn(data_loader,model,optimizer,device,scheduler):\n    model.train()\n    final_loss = 0\n    for data in tqdm(data_loader):\n        ids = data[\"ids\"].to(device)\n        mask = data[\"mask\"].to(device)\n        token_type_ids = data[\"token_type_ids\"].to(device)\n        target_ner = data[\"target_ner\"].to(device)\n        optimizer.zero_grad()\n        _,loss,acc,_ = model(ids, mask, token_type_ids, target_ner)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        final_loss += loss.item()\n    return final_loss/len(data_loader), acc\n\ndef eval_fn(data_loader,model,device):\n    model.eval()\n    final_loss = 0\n    for data in tqdm(data_loader):\n        ids = data[\"ids\"].to(device)\n        mask = data[\"mask\"].to(device)\n        token_type_ids = data[\"token_type_ids\"].to(device)\n        target_ner = data[\"target_ner\"].to(device)\n        _,loss,acc,f1 = model(ids, mask, token_type_ids, target_ner)\n        final_loss +=loss.item()\n    return final_loss/len(data_loader),acc,f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.125854Z","iopub.execute_input":"2024-12-17T03:34:03.126096Z","iopub.status.idle":"2024-12-17T03:34:03.137361Z","shell.execute_reply.started":"2024-12-17T03:34:03.126066Z","shell.execute_reply":"2024-12-17T03:34:03.136487Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"    # output: Tensor đầu ra từ mô hình, kích thước là [batch_size,max_len,num_labels]\n    #         Mỗi token có một vector logit đại diện cho xác suất thuộc về từng nhãn \n    # target: Tensor chứa nhãn thực tế, kích thước [batch_size, max_len]\n    # mask : Tensor đánh dấu giá trị có thực hay không, 0 là các padding còn 1 là các token thật\n    #         kích thước là [batch_size,max_len]\n    # num_labels: Số lượng nhãn mà mô hình có thể dự đoán\n    \ndef loss_fn(output, target, mask, num_labels):\n        lfn = nn.CrossEntropyLoss(ignore_index=1)\n        #Tất cả nhãn dán bằng 1 sẽ bị bỏ qua khi tính loss, \n        #trong bài toán NER thì [1] thường là các padđing trong ids\n        active_loss = mask.view(-1) == 1\n        # Chuyển ma trận kích thước batch_size, max_len thành ma trận có kích thước batch_size x max_len \n        # Khi so sánh với == 1 sẽ trả về một ma trận boolean với True là token hợp lệ và ngược lại\n        active_logits = output.view(-1, num_labels)  #Logit của các token hợp lệ\n        # Output đầu ra có kích thước batch_size,max_len,num_labels, qua biến đổi sẽ có kích thước là \n        # batch_size x max_len, num_labels\n        active_labels = torch.where(\n            active_loss,\n            target.view(-1),#Lấy nhãn nếu token hợp lệ\n            torch.tensor(1).type_as(target) #Gãn nhãn là padding nếu token không hợp lệ\n        )\n        # tôi muốn hỏi là như vậy thì hàm CrossEntropy khi làm với các bài toán NER sẽ được tính bằng active logits và active labels à ?\n        # Active loss là một tensor có dạng [True, True, False, True]\n        # Biến đổi target thành ma trận 1 chiều\n        # Tạo ra một tensor có kích thước bằng target nhưng toàn là số một \n        # Dùng torch.where để lấy ra kết quả theo tensor của active_loss nếu là True thì lấy giá trị của\n        # target còn nếu là False sẽ lấy kết quả của torch.tensor(1) tức là 1\n        loss = lfn(active_logits, active_labels)\n        return loss\n\ndef acc_fn(output,target,mask,num_labels):\n        _,predicted = torch.max(output,2)\n        #Chọn nhãn có xác suất cao nhất từ output theo chiều thứ 2 Ví dụ có \n        # tensor [\n    #     [[0.1, 0.8, 0.1], [0.3, 0.4, 0.3]],\n    #     [[0.6, 0.2, 0.2], [0.1, 0.7, 0.2]]\n    # ] \n        # sẽ trả về kết quả là [[1,1],[0,1]]\n        correct = (predicted == target) & (target != 1) & (mask == 1)\n        # So sánh nhãn dự đoán với nhãn thực tế, trả về True nếu trùng\n        # Chỉ xét các token là hợp lệ là các token khác [1] giống với các padding trong ids của bài toán NER\n        # Chỉ xét các token là các token hợp lệ trong mask và thực hiện toán tử là AND để lấy các toán tử đúng\n        # Ví dụ có tensor: \n        # predicted = torch.tensor([[0, 1], [1, 0]])\n        # target = torch.tensor([[0, 1], [1, 1]])\n        # mask = torch.tensor([[1, 1], [1, 0]])\n        # Kết quả sẽ là [[True,False],[False,False]]\n        num_correct = correct.sum().item()\n        # đếm tổng các số lượng True trong correct \n        # Kết quả là tổng số token được dự đoán đúng trong batch\n        num_samples = target[(target != 1)& (mask == 1)].size()[0]\n        # Lọc ra các token hợp lệ trong thực tế (loại bỏ các token là [1](các token là padding) và lấy các token hợp lệ của mask)\n        # size()[0] dùng để tính tổng các token hợp lệ\n        accuracy = num_correct/num_samples if num_samples > 0 else 0.0\n        return accuracy\n    \ndef f1_score_fn(output,target,mask,num_labels):\n        active_loss = mask.view(-1) == 1\n        active_logits = output.view(-1,num_labels)\n        active_labels = torch.where(\n            active_loss,\n            target.view(-1),\n            torch.tensor(1).type_as(target)\n        )\n        f1 = multiclass_f1_score(active_logits,active_labels,num_classes = num_labels,average = \"macro\")\n        # Công thức hàm f1 score gồm input, target, num_class và average\n        return f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.138730Z","iopub.execute_input":"2024-12-17T03:34:03.139061Z","iopub.status.idle":"2024-12-17T03:34:03.152022Z","shell.execute_reply.started":"2024-12-17T03:34:03.139016Z","shell.execute_reply":"2024-12-17T03:34:03.151278Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"sentences,ner,enc_ner = process_data(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.153499Z","iopub.execute_input":"2024-12-17T03:34:03.154018Z","iopub.status.idle":"2024-12-17T03:34:03.423038Z","shell.execute_reply.started":"2024-12-17T03:34:03.153981Z","shell.execute_reply":"2024-12-17T03:34:03.422351Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"for label,encode_value in zip(enc_ner.classes_,enc_ner.transform(enc_ner.classes_)):\n    print(f\"{label} -> {encode_value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.423905Z","iopub.execute_input":"2024-12-17T03:34:03.424163Z","iopub.status.idle":"2024-12-17T03:34:03.429190Z","shell.execute_reply.started":"2024-12-17T03:34:03.424138Z","shell.execute_reply":"2024-12-17T03:34:03.428238Z"}},"outputs":[{"name":"stdout","text":"B-AGE -> 0\nB-DATE -> 1\nB-GENDER -> 2\nB-JOB -> 3\nB-LOCATION -> 4\nB-NAME -> 5\nB-ORGANIZATION -> 6\nB-PATIENT_ID -> 7\nB-SYMPTOM_AND_DISEASE -> 8\nB-TRANSPORTATION -> 9\nI-AGE -> 10\nI-DATE -> 11\nI-JOB -> 12\nI-LOCATION -> 13\nI-NAME -> 14\nI-ORGANIZATION -> 15\nI-PATIENT_ID -> 16\nI-SYMPTOM_AND_DISEASE -> 17\nI-TRANSPORTATION -> 18\nO -> 19\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"num_ner = len(enc_ner.classes_)\nprint(num_ner)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.430241Z","iopub.execute_input":"2024-12-17T03:34:03.430527Z","iopub.status.idle":"2024-12-17T03:34:03.440304Z","shell.execute_reply.started":"2024-12-17T03:34:03.430496Z","shell.execute_reply":"2024-12-17T03:34:03.439619Z"}},"outputs":[{"name":"stdout","text":"20\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"(train_sentences,valid_sentences,train_ner,valid_ner) = model_selection.train_test_split(sentences,ner,random_state = 42, train_size=0.8)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.441320Z","iopub.execute_input":"2024-12-17T03:34:03.441577Z","iopub.status.idle":"2024-12-17T03:34:03.451855Z","shell.execute_reply.started":"2024-12-17T03:34:03.441554Z","shell.execute_reply":"2024-12-17T03:34:03.451112Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_dataset = COVIDDataset(train_sentences,train_ner)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset,batch_size = config.TRAIN_BATCH_SIZE,shuffle=True)\nvalid_dataset = COVIDDataset(valid_sentences,valid_ner)\nvalid_dataloader = torch.utils.data.DataLoader(valid_dataset,batch_size = config.VALID_BATCH_SIZE,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.452748Z","iopub.execute_input":"2024-12-17T03:34:03.452975Z","iopub.status.idle":"2024-12-17T03:34:03.462836Z","shell.execute_reply.started":"2024-12-17T03:34:03.452952Z","shell.execute_reply":"2024-12-17T03:34:03.462115Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class COVIDModel(nn.Module):\n    def __init__(self,num_ner):\n        super(COVIDModel,self).__init__()\n        self.num_ner = num_ner\n        self.bert = transformers.AutoModel.from_pretrained(config.BASE_MODEL)\n        self.dropout = nn.Dropout(0.1)\n        self.out_ner = nn.Linear(768,self.num_ner)\n    def forward(self,ids,mask,token_type_ids,target_ner):\n        outputs = self.bert(\n            ids,\n            attention_mask = mask,\n            token_type_ids = token_type_ids\n        )\n        o1 = outputs[\"last_hidden_state\"]\n        bo_ner = self.dropout(o1)\n        \n        ner = self.out_ner(bo_ner)\n        \n        loss_ner = loss_fn(ner, target_ner.to(ner.device), mask.to(ner.device), self.num_ner)\n\n        acc_ner = acc_fn(ner,target_ner,mask,self.num_ner)\n\n        f1 = f1_score_fn(ner,target_ner,mask,self.num_ner)\n\n        return ner,loss_ner,acc_ner,f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.463631Z","iopub.execute_input":"2024-12-17T03:34:03.463887Z","iopub.status.idle":"2024-12-17T03:34:03.472189Z","shell.execute_reply.started":"2024-12-17T03:34:03.463864Z","shell.execute_reply":"2024-12-17T03:34:03.471510Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"model = COVIDModel(num_ner)\nmodel.to(device)\n\nparam_optimizer = list(model.named_parameters())\nno_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\noptimizer_grouped_parameters = [\n    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n]\nnum_train_steps = int(\n    len(train_sentences) / config.TRAIN_BATCH_SIZE * config.EPOCH\n)\noptimizer = AdamW(optimizer_grouped_parameters, lr=1e-5)\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0, \n    num_training_steps=num_train_steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:03.473123Z","iopub.execute_input":"2024-12-17T03:34:03.473385Z","iopub.status.idle":"2024-12-17T03:34:17.962284Z","shell.execute_reply.started":"2024-12-17T03:34:03.473341Z","shell.execute_reply":"2024-12-17T03:34:17.961349Z"},"scrolled":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7911e82e0bf8409dbba20f47d331f1d1"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"train_losses = []\nvalid_losses = []\nbest_loss = np.inf\nfor epoch in range(config.EPOCH):\n    train_loss, train_acc = train_fn(train_dataloader,model,optimizer,device,scheduler)\n    valid_loss, valid_acc, f1_score = eval_fn(valid_dataloader,model,device)\n    print(f\"Epoch: {epoch+1} - Train Loss: {train_loss} - Train Accuracy: {train_acc}\")\n    print(f\"Epoch: {epoch+1} - Valid Loss: {valid_loss} - Valid Accuracy: {valid_acc} - F1 score: {f1_score}\")\n    train_losses.append(train_loss)\n    valid_losses.append(valid_loss)\n    if valid_loss<best_loss:\n        best_loss = valid_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:34:17.963517Z","iopub.execute_input":"2024-12-17T03:34:17.964496Z","iopub.status.idle":"2024-12-17T03:53:56.628413Z","shell.execute_reply.started":"2024-12-17T03:34:17.964433Z","shell.execute_reply":"2024-12-17T03:53:56.627599Z"}},"outputs":[{"name":"stderr","text":"  4%|▎         | 9/249 [00:02<00:57,  4.19it/s]","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/540M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e61d62f38b084766926a90ceb0ac1f6e"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 249/249 [00:55<00:00,  4.50it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 1 - Train Loss: 0.8829921184773426 - Train Accuracy: 0.9436936936936937\nEpoch: 1 - Valid Loss: 0.4260216137719533 - Valid Accuracy: 0.9333333333333333 - F1 score: 0.4358093738555908\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:53<00:00,  4.63it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.11it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 2 - Train Loss: 0.34014162858087854 - Train Accuracy: 0.9727272727272728\nEpoch: 2 - Valid Loss: 0.2291064943586077 - Valid Accuracy: 0.984 - F1 score: 0.6908043026924133\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:53<00:00,  4.62it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.77it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 3 - Train Loss: 0.21007658134263205 - Train Accuracy: 0.976303317535545\nEpoch: 3 - Valid Loss: 0.16005880693121563 - Valid Accuracy: 0.9827586206896551 - F1 score: 0.5819923877716064\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.53it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 4 - Train Loss: 0.15606335771969523 - Train Accuracy: 0.9682151589242054\nEpoch: 4 - Valid Loss: 0.1298980818144859 - Valid Accuracy: 0.9591836734693877 - F1 score: 0.4420969486236572\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.54it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 5 - Train Loss: 0.12224419845874052 - Train Accuracy: 0.9895833333333334\nEpoch: 5 - Valid Loss: 0.1176900038170436 - Valid Accuracy: 1.0 - F1 score: 0.799248993396759\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 6 - Train Loss: 0.10175339074199458 - Train Accuracy: 0.9957716701902748\nEpoch: 6 - Valid Loss: 0.09763523386347861 - Valid Accuracy: 0.9847328244274809 - F1 score: 0.7044234871864319\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.58it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 7 - Train Loss: 0.08520340151995061 - Train Accuracy: 0.9797101449275363\nEpoch: 7 - Valid Loss: 0.08823035142961003 - Valid Accuracy: 0.9854014598540146 - F1 score: 0.6106010675430298\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.58it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 8 - Train Loss: 0.07314040251525052 - Train Accuracy: 0.9965277777777778\nEpoch: 8 - Valid Loss: 0.08035702305653739 - Valid Accuracy: 0.9733333333333334 - F1 score: 0.5231986045837402\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.58it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.96it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 9 - Train Loss: 0.0646099025181618 - Train Accuracy: 0.9966555183946488\nEpoch: 9 - Valid Loss: 0.07675454999128031 - Valid Accuracy: 0.9852941176470589 - F1 score: 0.6169127821922302\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 10 - Train Loss: 0.05716112335343437 - Train Accuracy: 1.0\nEpoch: 10 - Valid Loss: 0.0782344691928417 - Valid Accuracy: 0.9923664122137404 - F1 score: 0.6492846012115479\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.58it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 11 - Train Loss: 0.051991825332363927 - Train Accuracy: 0.9978118161925602\nEpoch: 11 - Valid Loss: 0.0701470049245963 - Valid Accuracy: 1.0 - F1 score: 0.7562559843063354\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.60it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 12 - Train Loss: 0.046826894967311836 - Train Accuracy: 0.9969604863221885\nEpoch: 12 - Valid Loss: 0.0749885563753427 - Valid Accuracy: 0.9871794871794872 - F1 score: 0.6531928181648254\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.83it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 13 - Train Loss: 0.04356471446892583 - Train Accuracy: 1.0\nEpoch: 13 - Valid Loss: 0.06882507048015084 - Valid Accuracy: 1.0 - F1 score: 0.7567568421363831\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.57it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 14 - Train Loss: 0.0400531128737103 - Train Accuracy: 1.0\nEpoch: 14 - Valid Loss: 0.06779371403039448 - Valid Accuracy: 1.0 - F1 score: 0.8037409782409668\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.55it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 15 - Train Loss: 0.03771661606852908 - Train Accuracy: 0.994475138121547\nEpoch: 15 - Valid Loss: 0.06786170406710534 - Valid Accuracy: 1.0 - F1 score: 0.8358869552612305\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.58it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 16 - Train Loss: 0.03582265368666515 - Train Accuracy: 0.9946236559139785\nEpoch: 16 - Valid Loss: 0.066983746468193 - Valid Accuracy: 0.9716981132075472 - F1 score: 0.643653929233551\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.91it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 17 - Train Loss: 0.03449504709162985 - Train Accuracy: 1.0\nEpoch: 17 - Valid Loss: 0.06677097005266992 - Valid Accuracy: 0.9791666666666666 - F1 score: 0.7072843313217163\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.95it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 18 - Train Loss: 0.0332948810132931 - Train Accuracy: 0.9975429975429976\nEpoch: 18 - Valid Loss: 0.06626613410041919 - Valid Accuracy: 1.0 - F1 score: 0.7600763440132141\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.60it/s]\n100%|██████████| 63/63 [00:04<00:00, 14.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 19 - Train Loss: 0.031683393982220365 - Train Accuracy: 0.9908814589665653\nEpoch: 19 - Valid Loss: 0.06678225233086518 - Valid Accuracy: 0.978021978021978 - F1 score: 0.7071689963340759\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 249/249 [00:54<00:00,  4.59it/s]\n100%|██████████| 63/63 [00:04<00:00, 13.94it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch: 20 - Train Loss: 0.03148315157591698 - Train Accuracy: 0.992\nEpoch: 20 - Valid Loss: 0.0661979949929648 - Valid Accuracy: 0.9927536231884058 - F1 score: 0.48771199584007263\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# Lưu lại trọng số của mô hình\ntorch.save(model.state_dict(), \"model_weights.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:56.629738Z","iopub.execute_input":"2024-12-17T03:53:56.629993Z","iopub.status.idle":"2024-12-17T03:53:57.441906Z","shell.execute_reply.started":"2024-12-17T03:53:56.629967Z","shell.execute_reply":"2024-12-17T03:53:57.441189Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Load lại mô hình\nmodel.load_state_dict(torch.load(\"model_weights.pth\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:57.443015Z","iopub.execute_input":"2024-12-17T03:53:57.443289Z","iopub.status.idle":"2024-12-17T03:53:57.897777Z","shell.execute_reply.started":"2024-12-17T03:53:57.443264Z","shell.execute_reply":"2024-12-17T03:53:57.896918Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/2842314141.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"model_weights.pth\"))\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":25},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:57.898862Z","iopub.execute_input":"2024-12-17T03:53:57.899132Z","iopub.status.idle":"2024-12-17T03:53:57.905293Z","shell.execute_reply.started":"2024-12-17T03:53:57.899107Z","shell.execute_reply":"2024-12-17T03:53:57.904513Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"COVIDModel(\n  (bert): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(64001, 768, padding_idx=1)\n      (position_embeddings): Embedding(258, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): RobertaPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (out_ner): Linear(in_features=768, out_features=20, bias=True)\n)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"file_path_test = \"/kaggle/input/ner-covid-19/test_word.conll\"\ndf_test = conll_to_dataframe(read_conll(file_path_test),columns)\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:57.906236Z","iopub.execute_input":"2024-12-17T03:53:57.906578Z","iopub.status.idle":"2024-12-17T03:53:58.079795Z","shell.execute_reply.started":"2024-12-17T03:53:57.906541Z","shell.execute_reply":"2024-12-17T03:53:58.078942Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"             Word         NER\n0              Từ           O\n1              24      B-DATE\n2               -      I-DATE\n3               7      I-DATE\n4             đến           O\n...           ...         ...\n85673   nhiệt_đới  I-LOCATION\n85674  trung_ương  I-LOCATION\n85675       cơ_sở  I-LOCATION\n85676    Đông_Anh  I-LOCATION\n85677           .           O\n\n[85678 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Từ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>B-DATE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>đến</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>85673</th>\n      <td>nhiệt_đới</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>85674</th>\n      <td>trung_ương</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>85675</th>\n      <td>cơ_sở</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>85676</th>\n      <td>Đông_Anh</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>85677</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>85678 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"df_test[\"NER\"] = df_test[\"NER\"].replace(np.nan,'nan')\ndf_test = df_test[df_test[\"NER\"].str.isupper()]\n\ndf_test = df_test[~uppercase_rows].reset_index(drop=True)\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:58.085108Z","iopub.execute_input":"2024-12-17T03:53:58.085708Z","iopub.status.idle":"2024-12-17T03:53:58.128114Z","shell.execute_reply.started":"2024-12-17T03:53:58.085680Z","shell.execute_reply":"2024-12-17T03:53:58.127318Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_23/1715021881.py:4: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n  df_test = df_test[~uppercase_rows].reset_index(drop=True)\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"             Word         NER\n0              Từ           O\n1              24      B-DATE\n2               -      I-DATE\n3               7      I-DATE\n4             đến           O\n...           ...         ...\n83923   nhiệt_đới  I-LOCATION\n83924  trung_ương  I-LOCATION\n83925       cơ_sở  I-LOCATION\n83926    Đông_Anh  I-LOCATION\n83927           .           O\n\n[83928 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Từ</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>B-DATE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>đến</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83923</th>\n      <td>nhiệt_đới</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>83924</th>\n      <td>trung_ương</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>83925</th>\n      <td>cơ_sở</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>83926</th>\n      <td>Đông_Anh</td>\n      <td>I-LOCATION</td>\n    </tr>\n    <tr>\n      <th>83927</th>\n      <td>.</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n<p>83928 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"sentence_number_test = 1\nsentence_column_test = []\n\nfor index,row in df_test.iterrows():\n    if row[\"Word\"] in {\".\",\"!\",\"?\"}:\n        sentence_number_test += 1\n    sentence_column_test.append(f\"Sentence: {sentence_number_test}\")\ndf_test[\"Sentence #\"] = sentence_column_test\ndf_test = df_test.reset_index(drop=True)\ndf_test","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:53:58.129395Z","iopub.execute_input":"2024-12-17T03:53:58.130034Z","iopub.status.idle":"2024-12-17T03:54:01.422535Z","shell.execute_reply.started":"2024-12-17T03:53:58.129994Z","shell.execute_reply":"2024-12-17T03:54:01.421660Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"             Word         NER      Sentence #\n0              Từ           O     Sentence: 1\n1              24      B-DATE     Sentence: 1\n2               -      I-DATE     Sentence: 1\n3               7      I-DATE     Sentence: 1\n4             đến           O     Sentence: 1\n...           ...         ...             ...\n83923   nhiệt_đới  I-LOCATION  Sentence: 2901\n83924  trung_ương  I-LOCATION  Sentence: 2901\n83925       cơ_sở  I-LOCATION  Sentence: 2901\n83926    Đông_Anh  I-LOCATION  Sentence: 2901\n83927           .           O  Sentence: 2902\n\n[83928 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n      <th>Sentence #</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Từ</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>B-DATE</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>đến</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>83923</th>\n      <td>nhiệt_đới</td>\n      <td>I-LOCATION</td>\n      <td>Sentence: 2901</td>\n    </tr>\n    <tr>\n      <th>83924</th>\n      <td>trung_ương</td>\n      <td>I-LOCATION</td>\n      <td>Sentence: 2901</td>\n    </tr>\n    <tr>\n      <th>83925</th>\n      <td>cơ_sở</td>\n      <td>I-LOCATION</td>\n      <td>Sentence: 2901</td>\n    </tr>\n    <tr>\n      <th>83926</th>\n      <td>Đông_Anh</td>\n      <td>I-LOCATION</td>\n      <td>Sentence: 2901</td>\n    </tr>\n    <tr>\n      <th>83927</th>\n      <td>.</td>\n      <td>O</td>\n      <td>Sentence: 2902</td>\n    </tr>\n  </tbody>\n</table>\n<p>83928 rows × 3 columns</p>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"df_test[\"NER\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:54:01.423739Z","iopub.execute_input":"2024-12-17T03:54:01.424098Z","iopub.status.idle":"2024-12-17T03:54:01.436120Z","shell.execute_reply.started":"2024-12-17T03:54:01.424060Z","shell.execute_reply":"2024-12-17T03:54:01.435231Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"NER\nO                        62271\nI-LOCATION                4809\nB-LOCATION                4349\nI-ORGANIZATION            1979\nB-PATIENT_ID              1963\nI-DATE                    1716\nB-DATE                    1622\nI-SYMPTOM_AND_DISEASE     1438\nB-SYMPTOM_AND_DISEASE     1115\nB-ORGANIZATION             758\nB-AGE                      565\nB-GENDER                   452\nB-NAME                     310\nB-TRANSPORTATION           189\nB-JOB                      167\nI-JOB                      112\nI-TRANSPORTATION            68\nI-PATIENT_ID                26\nI-NAME                      13\nI-AGE                        6\nName: count, dtype: int64"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"def processing_data(df):\n    sentences = df.groupby(\"Sentence #\")[\"Word\"].apply(list).values\n    ner = df.groupby(\"Sentence #\")[\"NER\"].apply(list).values\n    return sentences, ner","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:54:01.437017Z","iopub.execute_input":"2024-12-17T03:54:01.437279Z","iopub.status.idle":"2024-12-17T03:54:01.445369Z","shell.execute_reply.started":"2024-12-17T03:54:01.437256Z","shell.execute_reply":"2024-12-17T03:54:01.444510Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Xử lí các ner không tồn tại trong ner train nếu không sẽ bị gặp lỗi unseenlabel\ndf_test_copy = df_test.copy()\n\nenc_ner_unknown = preprocessing.LabelEncoder()\nenc_ner_unknown.classes_ = np.append(enc_ner.classes_,\"unknown\")\n\nunseen_ner = set(df_test_copy[\"NER\"]) -  set(enc_ner.classes_)\ndf_test_copy.loc[:,\"NER\"] = df_test_copy[\"NER\"].replace(unseen_ner,\"unknown\")\n\ndf_test_copy.loc[:,\"NER\"] = enc_ner_unknown.fit_transform(df_test_copy[\"NER\"])\n\nsentences_test, ner_test = processing_data(df_test_copy)\ntest_dataset = COVIDDataset(sentences_test,ner_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:54:01.446256Z","iopub.execute_input":"2024-12-17T03:54:01.446539Z","iopub.status.idle":"2024-12-17T03:54:01.598198Z","shell.execute_reply.started":"2024-12-17T03:54:01.446515Z","shell.execute_reply":"2024-12-17T03:54:01.597290Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# model = COVIDModel(num_ner)\n# model.load_state_dict(torch.load(\"model_weights.pth\"))\n# model.to(device)\n\nwith torch.no_grad():\n    data = test_dataset[0]\n    for k, v in data.items():\n        data[k] = v.to(device).unsqueeze(0)\n    ner_test, _, acc, f1_score = model(**data)\n    predict_ner = enc_ner.inverse_transform(\n        np.clip(ner_test.argmax(2).cpu().numpy().reshape(-1), 0, len(enc_ner.classes_) - 1))[:data['ids'].size(1)]\n    print(print(f\"Test Accuracy: {acc:.4f}, Test F1-score: {f1_score:.4f}\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:54:01.599286Z","iopub.execute_input":"2024-12-17T03:54:01.599554Z","iopub.status.idle":"2024-12-17T03:54:01.632517Z","shell.execute_reply.started":"2024-12-17T03:54:01.599529Z","shell.execute_reply":"2024-12-17T03:54:01.631710Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 0.9400, Test F1-score: 0.5614\nNone\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"df_test_new = df_test.iloc[:len(predict_ner)].copy()\ndf_test_new[\"predict_ner\"] = predict_ner\ndf_test_new[:20]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:55:32.566768Z","iopub.execute_input":"2024-12-17T03:55:32.567758Z","iopub.status.idle":"2024-12-17T03:55:32.584358Z","shell.execute_reply.started":"2024-12-17T03:55:32.567709Z","shell.execute_reply":"2024-12-17T03:55:32.583442Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"     Word     NER   Sentence # predict_ner\n0      Từ       O  Sentence: 1           O\n1      24  B-DATE  Sentence: 1           O\n2       -  I-DATE  Sentence: 1      I-DATE\n3       7  I-DATE  Sentence: 1      I-DATE\n4     đến       O  Sentence: 1      I-DATE\n5      31  B-DATE  Sentence: 1           O\n6       -  I-DATE  Sentence: 1      I-DATE\n7       7  I-DATE  Sentence: 1      I-DATE\n8       ,       O  Sentence: 1      I-DATE\n9    được       O  Sentence: 1           O\n10     mẹ       O  Sentence: 1           O\n11     là       O  Sentence: 1           O\n12     bà       O  Sentence: 1           O\n13  H.T.P  B-NAME  Sentence: 1           O\n14      (       O  Sentence: 1      B-NAME\n15     47   B-AGE  Sentence: 1      B-NAME\n16   tuổi       O  Sentence: 1           O\n17      )       O  Sentence: 1       B-AGE\n18    đón       O  Sentence: 1           O\n19     về       O  Sentence: 1           O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>NER</th>\n      <th>Sentence #</th>\n      <th>predict_ner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Từ</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24</td>\n      <td>B-DATE</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>đến</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>31</td>\n      <td>B-DATE</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>-</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>I-DATE</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>,</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>I-DATE</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>được</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>mẹ</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>là</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>bà</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>H.T.P</td>\n      <td>B-NAME</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>B-NAME</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>47</td>\n      <td>B-AGE</td>\n      <td>Sentence: 1</td>\n      <td>B-NAME</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>tuổi</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>)</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>B-AGE</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>đón</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>về</td>\n      <td>O</td>\n      <td>Sentence: 1</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"#Test a sentence\n# !pip install py_vncorenlp","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T03:54:01.646368Z","iopub.execute_input":"2024-12-17T03:54:01.646638Z","iopub.status.idle":"2024-12-17T03:54:12.028190Z","shell.execute_reply.started":"2024-12-17T03:54:01.646614Z","shell.execute_reply":"2024-12-17T03:54:12.027248Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting py_vncorenlp\n  Downloading py_vncorenlp-0.1.4.tar.gz (3.9 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting pyjnius (from py_vncorenlp)\n  Downloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nDownloading pyjnius-1.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: py_vncorenlp\n  Building wheel for py_vncorenlp (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for py_vncorenlp: filename=py_vncorenlp-0.1.4-py3-none-any.whl size=4305 sha256=5ccbf4e9aa0b6a0b9ee383a5a4a8efb73e7e26249aa9a52417165fb4d5dd2c7b\n  Stored in directory: /root/.cache/pip/wheels/d5/d9/bf/62632cdb007c702a0664091e92a0bb1f18a2fcecbe962d9827\nSuccessfully built py_vncorenlp\nInstalling collected packages: pyjnius, py_vncorenlp\nSuccessfully installed py_vncorenlp-0.1.4 pyjnius-1.6.1\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"# !apt-get update -qq\n# !apt-get install -y openjdk-11-jdk-headless -qq > /dev/null","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:11:26.532277Z","iopub.execute_input":"2024-12-17T04:11:26.532903Z","iopub.status.idle":"2024-12-17T04:11:32.608179Z","shell.execute_reply.started":"2024-12-17T04:11:26.532869Z","shell.execute_reply":"2024-12-17T04:11:32.607128Z"}},"outputs":[{"name":"stdout","text":"W: https://packages.cloud.google.com/apt/dists/gcsfuse-focal/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\nW: https://packages.cloud.google.com/apt/dists/google-fast-socket/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"# import py_vncorenlp\n\n# Automatically download VnCoreNLP components from the original repository\n# and save them in some local machine folder\n# save_dir = \"/kaggle/working/\"\n# py_vncorenlp.download_model(save_dir=save_dir)\n\n# Load the word and sentence segmentation component\n# rdrsegmenter = py_vncorenlp.VnCoreNLP(annotators=[\"wseg\"],save_dir=save_dir)\n\n# output_text = rdrsegmenter.word_segment(text)\n\ntext = \"\"\"Ông Nguyễn_Văn_Công đã bắt_đầu làm việc ở Bệnh_viện nhiệt_đới trung_ương.\"\"\"\nprint(text)\n\ntokenize_sentence = config.TOKENIZE.encode(text)\nprint(tokenize_sentence)\nsentence_text = text.split()\n\ntext_dataset = COVIDDataset(\n    word = [sentence_text],\n    ner = [[1]*len(sentence_text)]\n)\nwith torch.no_grad():\n    data = text_dataset[0]\n    for k, v in data.items():\n        data[k] = v.to(device).unsqueeze(0)\n    ner, _, _, _ = model(**data)\npredicted_ner = enc_ner.inverse_transform(\n                        ner.argmax(2).cpu().numpy().reshape(-1))[:len(tokenize_sentence)]\nprint(predicted_ner)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-17T04:32:42.273464Z","iopub.execute_input":"2024-12-17T04:32:42.273841Z","iopub.status.idle":"2024-12-17T04:32:42.295009Z","shell.execute_reply.started":"2024-12-17T04:32:42.273809Z","shell.execute_reply":"2024-12-17T04:32:42.293994Z"}},"outputs":[{"name":"stdout","text":"Ông Nguyễn_Văn_Công đã bắt_đầu làm việc ở Bệnh_viện nhiệt_đới trung_ương.\n[0, 168, 34449, 14, 403, 47, 49, 25, 1089, 5167, 12965, 16820, 10838, 2]\n['O' 'O' 'B-NAME' 'O' 'O' 'O' 'O' 'O' 'B-LOCATION' 'I-LOCATION'\n 'I-LOCATION' 'I-LOCATION' 'I-LOCATION' 'O']\n","output_type":"stream"}],"execution_count":63}]}